{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0pLksJVrK4i_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_AFBT-tAK82T"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"new_df.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hscQ-g2LbfE"
   },
   "source": [
    "### 주어진 df ->  tf-idf 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7Z_lzzFLKoK",
    "outputId": "6046e827-04e1-44ef-a16e-052d8024c03c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 벡터화 결과:\n",
      "        건강        검정   경보       경찰청   관리   그늘   금지        되다  물놀이       바라다  \\\n",
      "0      0.0  0.000000  0.0  0.707698  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "1      0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.313276   \n",
      "2      0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.855446  0.0  0.517892   \n",
      "3      0.0  0.627727  0.0  0.550896  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "4      0.0  0.849887  0.0  0.372932  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "...    ...       ...  ...       ...  ...  ...  ...       ...  ...       ...   \n",
      "21835  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.171697   \n",
      "21836  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.654018   \n",
      "21837  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.733854  0.0  0.444279   \n",
      "21838  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.491296   \n",
      "21839  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.654018   \n",
      "\n",
      "       ...   준수        지역   착용        찾다  충분하다   폭염        하다        하천   활동  \\\n",
      "0      ...  0.0  0.000000  0.0  0.706515   0.0  0.0  0.000000  0.000000  0.0   \n",
      "1      ...  0.0  0.000000  0.0  0.000000   0.0  0.0  0.362355  0.000000  0.0   \n",
      "2      ...  0.0  0.000000  0.0  0.000000   0.0  0.0  0.000000  0.000000  0.0   \n",
      "3      ...  0.0  0.000000  0.0  0.549975   0.0  0.0  0.000000  0.000000  0.0   \n",
      "4      ...  0.0  0.000000  0.0  0.372309   0.0  0.0  0.000000  0.000000  0.0   \n",
      "...    ...  ...       ...  ...       ...   ...  ...       ...       ...  ...   \n",
      "21835  ...  0.0  0.626919  0.0  0.000000   0.0  0.0  0.000000  0.360482  0.0   \n",
      "21836  ...  0.0  0.000000  0.0  0.000000   0.0  0.0  0.756479  0.000000  0.0   \n",
      "21837  ...  0.0  0.000000  0.0  0.000000   0.0  0.0  0.513881  0.000000  0.0   \n",
      "21838  ...  0.0  0.000000  0.0  0.000000   0.0  0.0  0.568263  0.000000  0.0   \n",
      "21839  ...  0.0  0.000000  0.0  0.000000   0.0  0.0  0.756479  0.000000  0.0   \n",
      "\n",
      "        휴식  \n",
      "0      0.0  \n",
      "1      0.0  \n",
      "2      0.0  \n",
      "3      0.0  \n",
      "4      0.0  \n",
      "...    ...  \n",
      "21835  0.0  \n",
      "21836  0.0  \n",
      "21837  0.0  \n",
      "21838  0.0  \n",
      "21839  0.0  \n",
      "\n",
      "[21840 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 텍스트 데이터와 라벨 분리\n",
    "texts = df['preprocessed_text']  # 'new_labeled_data' 대신 'df' 사용\n",
    "labels = df['label']  # 동일하게 'df'에서 라벨 가져오기\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "vectorizer = TfidfVectorizer(max_features=30)  # 상위 30개 단어만 사용\n",
    "vectored_df = vectorizer.fit_transform(texts)\n",
    "\n",
    "# 희소 행렬 -> 밀집 행렬 변환\n",
    "dense_df = vectored_df.todense()\n",
    "\n",
    "# 특징 이름 가져오기\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# DataFrame으로 변환\n",
    "df_tfidf = pd.DataFrame(dense_df, columns=feature_names)\n",
    "\n",
    "print(\"TF-IDF 벡터화 결과:\")\n",
    "print(df_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdlGm21oNoUk"
   },
   "source": [
    "### 데이터분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SqA6L2hpNpmF",
    "outputId": "42ca72ec-46b7-4ca4-f7d2-4b4fd60ee972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Validation/Test 데이터 분리 완료\n",
      "훈련 데이터 크기: (13104, 30), (13104,)\n",
      "검증 데이터 크기: (4368, 30), (4368,)\n",
      "테스트 데이터 크기: (4368, 30), (4368,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train/Validation/Test 데이터 분리\n",
    "X = df_tfidf  # TF-IDF 벡터화된 데이터\n",
    "y = df['label']  # 라벨 데이터\n",
    "\n",
    "# 먼저 Train/Test+Validation으로 나누기\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Validation/Test로 나누기\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Train/Validation/Test 데이터 분리 완료\")\n",
    "print(f\"훈련 데이터 크기: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"검증 데이터 크기: {X_valid.shape}, {y_valid.shape}\")\n",
    "print(f\"테스트 데이터 크기: {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnCoHwZ0dXfS"
   },
   "source": [
    "#랜덤포레스트 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3j8HGpxwONkJ",
    "outputId": "ab114afb-dd0f-4adc-eb5f-94f5b632cbba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score: 0.723\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.54      0.53      0.53       498\n",
      "           4       0.86      0.91      0.89       400\n",
      "           8       0.51      0.55      0.53       247\n",
      "           9       0.91      0.89      0.90       235\n",
      "          10       0.56      0.60      0.57       168\n",
      "          13       0.91      0.87      0.89       150\n",
      "          18       0.68      0.51      0.58       162\n",
      "          30       0.96      0.98      0.97       433\n",
      "          31       0.66      0.74      0.70       318\n",
      "          32       0.64      0.57      0.60       313\n",
      "          33       0.87      0.42      0.57       449\n",
      "          34       0.71      0.97      0.82       616\n",
      "          35       0.64      0.66      0.65       379\n",
      "\n",
      "    accuracy                           0.72      4368\n",
      "   macro avg       0.73      0.71      0.71      4368\n",
      "weighted avg       0.73      0.72      0.71      4368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Random Forest 기본 모델 학습\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 검증 데이터 예측\n",
    "y_valid_hat = rf.predict(X_valid)\n",
    "\n",
    "# 검증 데이터 평가\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "print(\"Validation Score: {:.3f}\".format(valid_accuracy))\n",
    "print(\"Classification Report:\\n\", classification_report(y_valid, y_valid_hat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFmKrVZ5dagg"
   },
   "source": [
    "#하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C5ewxAuAOSg2",
    "outputId": "587ac893-a7e1-4d50-cd96-ed0903751185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "540 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "135 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "405 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.70749315 0.70840895 0.70932466\n",
      " 0.70818026 0.709096   0.71031699 0.70772224 0.70932477 0.70879057\n",
      " 0.70589071 0.70779846 0.70810375 0.70734071 0.70756954 0.70718801\n",
      " 0.7048986  0.70573801 0.7053567  0.69543572 0.6961989  0.69680945\n",
      " 0.69543572 0.6961989  0.69680945 0.69291731 0.6931464  0.69459643\n",
      " 0.70726446 0.70856165 0.70856165 0.71115634 0.71062234 0.71138532\n",
      " 0.70894368 0.71039336 0.70940134 0.70444067 0.70474596 0.70680633\n",
      " 0.70482232 0.70497482 0.7043646  0.70390661 0.70390676 0.7032198\n",
      " 0.69413827 0.69406197 0.69451992 0.69413827 0.69406197 0.69451992\n",
      " 0.69352761 0.69276478 0.69284115        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66933663 0.67231279 0.67376262 0.66964194 0.6711681  0.67147327\n",
      " 0.66674185 0.66964174 0.66964168 0.66834461 0.67009961 0.67063355\n",
      " 0.66857359 0.66987069 0.67002327 0.66567352 0.66735262 0.66910765\n",
      " 0.66361318 0.66513935 0.66636049 0.66361318 0.66513935 0.66636049\n",
      " 0.66330807 0.66399463 0.66491046 0.67353367 0.67406779 0.67360995\n",
      " 0.6704051  0.67223652 0.671397   0.67132083 0.67063384 0.6704048\n",
      " 0.6686496  0.67025222 0.66971816 0.66765779 0.66910768 0.66834467\n",
      " 0.66628415 0.66636023 0.6681156  0.66445253 0.66468136 0.66368943\n",
      " 0.66445253 0.66468136 0.66368943 0.6604844  0.66277369 0.66185795\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.70787494 0.70840909 0.7083327\n",
      " 0.70764579 0.70833246 0.70787477 0.70497471 0.7056617  0.70619596\n",
      " 0.70474608 0.70688293 0.70703534 0.70222757 0.7034486  0.70482238\n",
      " 0.70047243 0.70222749 0.70253274 0.69474916 0.69566484 0.69658047\n",
      " 0.69474916 0.69566484 0.69658047 0.69322268 0.69368055 0.69444373\n",
      " 0.7079509  0.70863778 0.7094009  0.70718798 0.70772207 0.70894303\n",
      " 0.70528019 0.70642497 0.70497479 0.70276158 0.7036774  0.70398275\n",
      " 0.70199839 0.70314311 0.70375365 0.69948015 0.70123547 0.70108274\n",
      " 0.6920018  0.69261208 0.6920779  0.6920018  0.69261208 0.6920779\n",
      " 0.69009364 0.69108612 0.69139108        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.70756954 0.71001165 0.71031682 0.70779881 0.71039339 0.71054586\n",
      " 0.70772213 0.70734045 0.70802759 0.70650131 0.70650125 0.707875\n",
      " 0.70802747 0.7086379  0.70711164 0.70474581 0.70512746 0.70497505\n",
      " 0.69558839 0.69642785 0.69642782 0.69558839 0.69642785 0.69642782\n",
      " 0.69299373 0.69284112 0.69482541 0.7074167  0.70879063 0.70917207\n",
      " 0.70879077 0.70955378 0.71008787 0.70726446 0.70901963 0.70818017\n",
      " 0.70398283 0.7048223  0.70604326 0.70619588 0.70512761 0.70451719\n",
      " 0.70329599 0.70321988 0.70314337 0.69429097 0.69390929 0.694291\n",
      " 0.69429097 0.69390929 0.694291   0.69352761 0.69314628 0.6926885 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Best Validation Score: 0.711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],          # 트리 개수\n",
    "    'max_features': ['auto', 'sqrt', 'log2'], # 피처 선택 방식\n",
    "    'max_depth': [None, 10, 20, 30],          # 트리 최대 깊이\n",
    "    'min_samples_split': [2, 5, 10],          # 노드 분할 최소 샘플 수\n",
    "    'min_samples_leaf': [1, 2, 4]             # 리프 노드 최소 샘플 수\n",
    "}\n",
    "\n",
    "# GridSearchCV 설정\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 학습 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터 및 최고 점수 출력\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Validation Score: {:.3f}\".format(grid_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s635mlktddf4"
   },
   "source": [
    "#최적 파라미터로 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxQVjVG_PC_u",
    "outputId": "8b21df4b-884a-4a5f-aaa9-0ad56580dff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.831\n",
      "Validation Accuracy: 0.722\n",
      "Classification Report (Validation):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.53      0.54      0.54       498\n",
      "           4       0.85      0.92      0.88       400\n",
      "           8       0.51      0.55      0.53       247\n",
      "           9       0.90      0.89      0.89       235\n",
      "          10       0.57      0.62      0.59       168\n",
      "          13       0.93      0.85      0.89       150\n",
      "          18       0.69      0.49      0.58       162\n",
      "          30       0.97      0.98      0.97       433\n",
      "          31       0.66      0.71      0.68       318\n",
      "          32       0.67      0.57      0.62       313\n",
      "          33       0.88      0.42      0.57       449\n",
      "          34       0.71      0.97      0.82       616\n",
      "          35       0.64      0.65      0.64       379\n",
      "\n",
      "    accuracy                           0.72      4368\n",
      "   macro avg       0.73      0.70      0.71      4368\n",
      "weighted avg       0.73      0.72      0.71      4368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 최적의 파라미터로 Random Forest 재학습\n",
    "best_params = grid_search.best_params_\n",
    "rf_optimized = RandomForestClassifier(**best_params, random_state=42)\n",
    "rf_optimized.fit(X_train, y_train)\n",
    "\n",
    "# 학습 데이터와 검증 데이터 예측\n",
    "y_train_hat = rf_optimized.predict(X_train)\n",
    "y_valid_hat = rf_optimized.predict(X_valid)\n",
    "\n",
    "# 학습 및 검증 정확도 계산\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Train Accuracy: {:.3f}\".format(train_accuracy))\n",
    "print(\"Validation Accuracy: {:.3f}\".format(valid_accuracy))\n",
    "print(\"Classification Report (Validation):\\n\", classification_report(y_valid, y_valid_hat))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
